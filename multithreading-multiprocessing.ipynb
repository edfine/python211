{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multithreading and Multiprocessing\n",
    "\n",
    "In this module, you'll learn\n",
    "\n",
    "- How much (or little) parallelism you can get with Python threads\n",
    "- How to use synchronization primitives with threading\n",
    "- How to use the multiprocessing module to better utilize multicore machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Threading: the Global Interpreter Lock\n",
    "\n",
    "- Only one Python thread active at a time\n",
    "- C libraries can release the GIL\n",
    "  - I/O libraries, NumPy, etc.\n",
    "- Python threads are real, preemptive OS threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python Threads\n",
    "\n",
    "`threading.Thread(target, args=(), kwargs=None)`\n",
    "- target - Python function to call\n",
    "- args, kwargs - arguments to function\n",
    "- can also subclass & override run()\n",
    "\n",
    "`target(*args, **kwargs)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic threading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press enter to begin: \n",
      "Enter something: asdf\n",
      "calculated squares up to 369188 * 369188 = 136,299,040,969 while you typed asdf\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "class MyThread(threading.Thread):\n",
    "    \n",
    "    def run(self):\n",
    "        self.text = input('Enter something: ')\n",
    "        \n",
    "input('Press enter to begin: ')\n",
    "thread = MyThread()\n",
    "thread.start()\n",
    "\n",
    "count, result = 1, 1\n",
    "\n",
    "while thread.is_alive():\n",
    "    result = count * count\n",
    "    count += 1\n",
    "        \n",
    "print(f'calculated squares up to {count} * {count} = {result:,} while you typed {thread.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classless threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press enter to begin: \n",
      "Enter something: asfd\n",
      "calculated squares up to 549958 * 549958 = 302,452,701,849 while you typed asfd\n"
     ]
    }
   ],
   "source": [
    "def cabbage():\n",
    "    global text\n",
    "    text = input('Enter something: ')\n",
    "    \n",
    "input('Press enter to begin: ')\n",
    "thread = threading.Thread(target=cabbage)\n",
    "thread.start()\n",
    "\n",
    "count, result = 1, 1\n",
    "\n",
    "while thread.is_alive():\n",
    "    result = count * count\n",
    "    count += 1\n",
    "    \n",
    "print(f'calculated squares up to {count} * {count} = {result:,} while you typed {text}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading for performance (?!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "APPID = '10d4440bbaa8581bb8da9bd1fbea5617'\n",
    "UNITS = 'metric'\n",
    "\n",
    "cities = [\n",
    "    'Boulder', 'Atlanta', 'San Francisco',\n",
    "    'Reno', 'Honolulu', 'Zurich', 'Dubai',\n",
    "    'Dublin','Stuttgart', 'Rome', 'Singapore', \n",
    "    'Bangalore', 'Hyderabad', 'Hong Kong',\n",
    "    'Durham', 'New Orleans', 'Portland',\n",
    "]\n",
    "\n",
    "def get_temp(city, temps, units=UNITS, appid=APPID):\n",
    "    qs = urlencode({\n",
    "        'q': city,\n",
    "        'units': units,\n",
    "        'appid': appid,\n",
    "    })\n",
    "    url = f'http://api.openweathermap.org/data/2.5/weather?{qs}'\n",
    "    with urlopen(url) as resp:\n",
    "        data = json.load(resp)\n",
    "        temps[city] = data['main']['temp']\n",
    "        \n",
    "def run_serially():\n",
    "    for city in cities:\n",
    "        get_temp(city, temps)\n",
    "        \n",
    "def run_threaded():\n",
    "    # Create the threads\n",
    "    threads = [\n",
    "        threading.Thread(target=get_temp, args=(c, temps), kwargs={'units': 'imperial'}) \n",
    "        for c in cities\n",
    "    ]\n",
    "\n",
    "    # start all threads\n",
    "    for thread in threads:\n",
    "        thread.start() # not run()\n",
    "\n",
    "    # wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is 23° in Atlanta\n",
      "it is 20° in Bangalore\n",
      "it is 7° in Boulder\n",
      "it is 31° in Dubai\n",
      "it is 13° in Dublin\n",
      "it is 27° in Durham\n",
      "it is 25° in Hong Kong\n",
      "it is 26° in Honolulu\n",
      "it is 29° in Hyderabad\n",
      "it is 23° in New Orleans\n",
      "it is 8° in Portland\n",
      "it is 11° in Reno\n",
      "it is 22° in Rome\n",
      "it is 13° in San Francisco\n",
      "it is 27° in Singapore\n",
      "it is 16° in Stuttgart\n",
      "it is 18° in Zurich\n",
      "CPU times: user 25.7 ms, sys: 11.1 ms, total: 36.8 ms\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temps = {}\n",
    "\n",
    "run_serially()\n",
    "\n",
    "for k, v in sorted(temps.items()):\n",
    "    print(f'it is {v:.0f}° in {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is 73° in Atlanta\n",
      "it is 68° in Bangalore\n",
      "it is 45° in Boulder\n",
      "it is 88° in Dubai\n",
      "it is 56° in Dublin\n",
      "it is 80° in Durham\n",
      "it is 76° in Hong Kong\n",
      "it is 78° in Honolulu\n",
      "it is 84° in Hyderabad\n",
      "it is 74° in New Orleans\n",
      "it is 47° in Portland\n",
      "it is 52° in Reno\n",
      "it is 72° in Rome\n",
      "it is 56° in San Francisco\n",
      "it is 80° in Singapore\n",
      "it is 62° in Stuttgart\n",
      "it is 65° in Zurich\n",
      "CPU times: user 41.6 ms, sys: 386 µs, total: 42 ms\n",
      "Wall time: 675 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temps = {}\n",
    "\n",
    "run_threaded()\n",
    "\n",
    "for k, v in sorted(temps.items()):\n",
    "    print(f'it is {v:.0f}° in {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.76 ms, sys: 279 µs, total: 8.04 ms\n",
      "Wall time: 85.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time get_temp('Zurich', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17*85.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronization primitives\n",
    "\n",
    "Like other threading libraries, Python has support for `Lock`s, `Event`s, and `Semaphore`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()\n",
    "lock.acquire()\n",
    "# critical work here \n",
    "lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do things with lock locked, will be released after block\n"
     ]
    }
   ],
   "source": [
    "# Better\n",
    "lock = threading.Lock()\n",
    "with lock:\n",
    "    print('Do things with lock locked, will be released after block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = threading.Semaphore(4)\n",
    "sem.acquire()\n",
    "# up to 4 threads could be running in here\n",
    "sem.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in up to 4 different threads\n"
     ]
    }
   ],
   "source": [
    "# Better\n",
    "sem = threading.Semaphore(4)\n",
    "with sem:\n",
    "    print('Running in up to 4 different threads')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronized queue class\n",
    "\n",
    "If you structure your threads to send/receive data rather than just _share_ data, you can use a `queue.Queue`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading \n",
    "\n",
    "def worker(q):\n",
    "    while True:\n",
    "        value = q.get()\n",
    "        print('I got a {}'.format(value))\n",
    "        if value is None:\n",
    "            print('Got none, so exiting')\n",
    "            break\n",
    "\n",
    "q = queue.Queue()\n",
    "thd = threading.Thread(target=worker, args=(q, ))\n",
    "thd.start()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got a Hello there\n"
     ]
    }
   ],
   "source": [
    "q.put('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got a General Kenobi\n"
     ]
    }
   ],
   "source": [
    "q.put('General Kenobi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thd.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got a None\n",
      "Got none, so exiting\n"
     ]
    }
   ],
   "source": [
    "q.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thd.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.handlers.QueueListener?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple thread pool\n",
    "\n",
    "(There is also a thread pool in `multiprocessing.pool.ThreadPool`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool:\n",
    "    def __init__(self, count):\n",
    "        self.count = count\n",
    "        self.job = queue.Queue()\n",
    "        self.result = queue.Queue()\n",
    "        self.threads = [\n",
    "            threading.Thread(target=self.worker)\n",
    "            for i in range(count)\n",
    "        ]\n",
    "        for t in self.threads:\n",
    "            # t.setDaemon(True)  # make the thread 'daemonic'\n",
    "            t.start()\n",
    "            \n",
    "    def worker(self):\n",
    "        while True:\n",
    "            job = self.job.get()\n",
    "            try:\n",
    "                result = job()\n",
    "            except Exception as err:\n",
    "                self.result.put((False, err))\n",
    "            else:\n",
    "                self.result.put((True, result))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs created!Starting job\n",
      "Starting job\n",
      "\n",
      "Starting job\n",
      "Starting job\n",
      "exiting job\n",
      "Starting job\n",
      "exiting job\n",
      "Starting job\n",
      "exiting job\n",
      "Starting job\n",
      "exiting job\n",
      "Starting job\n",
      "exiting job\n",
      "Starting job\n",
      "exiting job\n",
      "Starting job\n",
      "exiting job\n",
      "exiting job\n",
      "exiting job\n",
      "exiting job\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(4)\n",
    "import time\n",
    "import random\n",
    "\n",
    "def job():\n",
    "    print('Starting job', flush=True)\n",
    "    time.sleep(3 + random.random())\n",
    "    print('exiting job', flush=True)\n",
    "\n",
    "for i in range(10):\n",
    "    pool.job.put(job)\n",
    "print('Jobs created!', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiprocessing with Python\n",
    "\n",
    "In this module, you'll learn\n",
    "\n",
    "- How to use the multiprocessing module \n",
    "- How to use multiprocessing's support for synchronization and communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiprocessing\n",
    "\n",
    "- Based on Threading\n",
    "- No GIL, no shared memory without extra work\n",
    "- Uses multicore well\n",
    "- Much more memory intensive than threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Multiprocessing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Process, cpu_count\n",
    "\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data/multi-test.py\n"
     ]
    }
   ],
   "source": [
    "%%file data/multi-test.py\n",
    "from multiprocessing import Process, cpu_count\n",
    "import time\n",
    "import os\n",
    "\n",
    "class MuchCPU(Process):\n",
    "    def run(self):\n",
    "        print(os.getpid())\n",
    "        for i in range(20_000_000):\n",
    "            result = i * i\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Running...')\n",
    "    procs = [MuchCPU() for f in range(cpu_count())]\n",
    "    # procs = [MuchCPU(), MuchCPU()]\n",
    "    t = time.time()\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "        # p.join()\n",
    "    \n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    \n",
    "    print('work took {} seconds'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "work took 27.10633397102356 seconds\n"
     ]
    }
   ],
   "source": [
    "!python data/multi-test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data/multi-test-2.py\n"
     ]
    }
   ],
   "source": [
    "%%file data/multi-test-2.py\n",
    "\n",
    "from multiprocessing import Process, cpu_count\n",
    "import time\n",
    "import os\n",
    "\n",
    "def target():\n",
    "    print(os.getpid())\n",
    "    for i in range(20_000_000):\n",
    "        result = i * i\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    print('Running...')\n",
    "    procs = [Process(target=target) for f in range(cpu_count())]\n",
    "    t = time.time()\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "        #p.join()\n",
    "\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "\n",
    "    print('work took {} seconds'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "work took 8.994603157043457 seconds\n"
     ]
    }
   ],
   "source": [
    "!python data/multi-test-2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def much_cpu(n):\n",
    "    # time.sleep(random.random())\n",
    "    \n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += i * i    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000,\n",
       " 2000]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_list = [2000] * 14\n",
    "args_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiprocessing.Pool\n",
    " \n",
    " - map(f, args) => list\n",
    " - imap(f, args) => iterator\n",
    " - imap_unordered(f, args) => iterator but unordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data/mp-pool.py\n"
     ]
    }
   ],
   "source": [
    "%%file data/mp-pool.py\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import random\n",
    "\n",
    "def much_cpu(n):\n",
    "    # time.sleep(random.random())\n",
    "    \n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += i * i    \n",
    "    return result\n",
    "\n",
    "args_list = [2000] * 20\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool() as p:\n",
    "        print(p.map(much_cpu, args_list))\n",
    "        for result in p.imap(much_cpu, args_list):\n",
    "            print(result)\n",
    "        print(sum(p.imap_unordered(much_cpu, args_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000, 2664667000]\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "2664667000\r\n",
      "53293340000\r\n"
     ]
    }
   ],
   "source": [
    "!python data/mp-pool.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo bar\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "p = multiprocessing.Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ar = p.apply_async(print, args=('foo', 'bar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n",
      "2664667000\n"
     ]
    }
   ],
   "source": [
    "args_list = [2000] * 20\n",
    "\n",
    "with ThreadPool(processes=16) as p:\n",
    "    for result in p.imap_unordered(much_cpu, args_list):\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiprocess synchronization and communication\n",
    "\n",
    "- Lock, Condition, Semaphore, Event\n",
    "- Queue & Pipe\n",
    "- Shared Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing basic shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "ROWS = 1_000_000\n",
    "COLS = 16\n",
    "\n",
    "X = [random.random() for i in range(ROWS * COLS)]\n",
    "Y = [random.random() for i in range(ROWS * COLS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mularray(X, Y):\n",
    "    return [x * y for x, y in zip(X, Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #1: single-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Z = mularray(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #2: multiprocess (pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [c * ROWS for c in range(COLS)]\n",
    "\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file data/mp-pmul.py\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "ROWS = 1_000_000\n",
    "COLS = 16\n",
    "\n",
    "pc_begin = time.perf_counter()\n",
    "\n",
    "X = [random.random() for i in range(ROWS * COLS)]\n",
    "Y = [random.random() for i in range(ROWS * COLS)]\n",
    "offsets = [c * ROWS for c in range(COLS)]\n",
    "\n",
    "pc_alloc = time.perf_counter()\n",
    "\n",
    "def mularray(X, Y):\n",
    "    return [x * y for x, y in zip(X, Y)]\n",
    "\n",
    "def pmul(offset):\n",
    "    return mularray(\n",
    "        X[offset:offset + ROWS], \n",
    "        Y[offset:offset + ROWS],\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Z = []\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        for Zpart in pool.imap(pmul, offsets):\n",
    "            Z += Zpart\n",
    "    pc_end = time.perf_counter()\n",
    "    print(f'Allocation in {pc_alloc - pc_begin}s')\n",
    "    print(f'Work done in {pc_end - pc_alloc}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!time python data/mp-pmul.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #3: multiprocess (pool), shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file data/mp-pmul-sm.py\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "ROWS = 1_000_000\n",
    "COLS = 16\n",
    "\n",
    "pc_begin = time.perf_counter()\n",
    "X = [random.random() for i in range(ROWS * COLS)]\n",
    "Y = [random.random() for i in range(ROWS * COLS)]\n",
    "offsets = [c * ROWS for c in range(COLS)]\n",
    "\n",
    "sX = multiprocessing.Array('f', X, lock=False)\n",
    "sY = multiprocessing.Array('f', Y, lock=False)\n",
    "sZ = multiprocessing.Array('f', ROWS * COLS, lock=False)\n",
    "pc_alloc = time.perf_counter()\n",
    "\n",
    "def pmul(offset):\n",
    "    for i in range(offset, offset + ROWS):\n",
    "        sZ[i] = sX[i] * sY[i]\n",
    "      \n",
    "if __name__ == '__main__':\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        for x in pool.imap_unordered(pmul, offsets):\n",
    "            pass\n",
    "    pc_end = time.perf_counter()\n",
    "    print(f'Allocation in {pc_alloc - pc_begin}s')\n",
    "    print(f'Work done in {pc_end - pc_alloc}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!time python data/mp-pmul-sm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #4: used `shared_memory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file data/mp-pmul-sm2.py\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "from multiprocessing import shared_memory\n",
    "from multiprocessing.managers import SharedMemoryManager\n",
    "\n",
    "pc_begin = time.perf_counter()\n",
    "\n",
    "ROWS = 1_000_000\n",
    "COLS = 16\n",
    "offsets = [c * ROWS for c in range(COLS)]\n",
    "\n",
    "def pmul(offset):\n",
    "    for i in range(offset, offset + ROWS):\n",
    "        Z[i] = X[i] * Y[i]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with SharedMemoryManager() as smm:\n",
    "        X = smm.ShareableList([random.random() for i in range(ROWS * COLS)])\n",
    "        Y = smm.ShareableList([random.random() for i in range(ROWS * COLS)])\n",
    "        Z = smm.ShareableList([0] * (ROWS * COLS))\n",
    "        pc_alloc = time.perf_counter()\n",
    "\n",
    "        with multiprocessing.Pool() as pool:\n",
    "            for x in pool.imap_unordered(pmul, offsets):\n",
    "                pass\n",
    "\n",
    "        pc_end = time.perf_counter()\n",
    "        print(f'Allocation in {pc_alloc - pc_begin}s')\n",
    "        print(f'Work done in {pc_end - pc_alloc}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!time python data/mp-pmul-sm2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: if you _really_ want it fast, just use numpy (or better yet, numpy + multithreading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random(ROWS * COLS)\n",
    "Y = np.random.random(ROWS * COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Z0 = X * Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "offsets = [c * ROWS for c in range(COLS)]\n",
    "Z1 = np.zeros_like(X)\n",
    "\n",
    "def pmul_numpy(offset):\n",
    "    Z1[offset:offset+ROWS] = X[offset:offset+ROWS] * Y[offset:offset+ROWS]\n",
    "\n",
    "with ThreadPool(processes=16) as p:\n",
    "    for result in p.imap_unordered(pmul_numpy, offsets):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Z0 == Z1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.managers import SharedMemoryManager\n",
    "\n",
    "offsets = [c * ROWS for c in range(COLS)]\n",
    "\n",
    "def pmul_numpy(offset):\n",
    "    aZ[offset:offset+ROWS] = aX[offset:offset+ROWS] * aY[offset:offset+ROWS]\n",
    "\n",
    "with SharedMemoryManager() as smm:\n",
    "    pc_begin = time.perf_counter()\n",
    "    sX = smm.SharedMemory(X.nbytes)\n",
    "    sY = smm.SharedMemory(X.nbytes)\n",
    "    sZ = smm.SharedMemory(X.nbytes)\n",
    "    aX = np.ndarray(X.shape, dtype=X.dtype, buffer=sX.buf)\n",
    "    aY = np.ndarray(X.shape, dtype=X.dtype, buffer=sY.buf)\n",
    "    aZ = np.ndarray(X.shape, dtype=X.dtype, buffer=sZ.buf)\n",
    "    aX[:] = X[:]\n",
    "    aY[:] = Y[:]\n",
    "    pc_alloc = time.perf_counter()\n",
    "\n",
    "    with Pool(processes=16) as p:\n",
    "        for result in p.imap_unordered(pmul_numpy, offsets):\n",
    "            pass\n",
    "    pc_end = time.perf_counter()\n",
    "\n",
    "    print(f'Allocation in {pc_alloc - pc_begin}s')\n",
    "    print(f'Work done in {pc_end - pc_alloc}s')\n",
    "    print((aZ == Z0).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab\n",
    "\n",
    "Open [concurrency lab][multithreading-multiprocessing-lab]\n",
    "\n",
    "[multithreading-multiprocessing-lab]: ./multithreading-multiprocessing-lab.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
